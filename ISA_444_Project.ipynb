{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ISA 444 Final Project\n",
        "# Daniel Woodward, Olivia Pisano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuU6bC1D0qzq",
        "outputId": "8da3eb02-ecb6-4c2c-f9c9-59d81de9e133"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Installation & Imports\n",
        "\n",
        "!pip install pandas numpy matplotlib seaborn statsforecast mlforecast neuralforecast lightgbm nixtla\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# StatsForecast\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "\n",
        "# MLForecast\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# NeuralForecast\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "\n",
        "# TimeGPT\n",
        "from nixtla import NixtlaClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3YjoYo83cd9",
        "outputId": "92193add-1ecc-4d59-f971-48a950bf97b2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Data Loading & Preprocessing (Fixed Date Frequency)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_and_prep_data():\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    # 1. Load CSVs\n",
        "    try:\n",
        "        train = pd.read_csv('Train.csv')\n",
        "        features = pd.read_csv('Features.csv')\n",
        "        test = pd.read_csv('Test.csv')\n",
        "        stores = pd.read_csv('Stores.csv')\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error finding file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # 2. Merge Dataframes\n",
        "    # Merge Store metadata and Features into Train\n",
        "    df = train.merge(stores, on='Store', how='left')\n",
        "    df = df.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "    # Merge Test data as well\n",
        "    test_df = test.merge(stores, on='Store', how='left')\n",
        "    test_df = test_df.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "    # 3. Handle Missing Values\n",
        "    # Markdowns: Fill with 0 (missing markdown = no promotion)\n",
        "    md_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "    df[md_cols] = df[md_cols].fillna(0)\n",
        "    test_df[md_cols] = test_df[md_cols].fillna(0)\n",
        "\n",
        "    # Economic Indicators: Interpolate (Fill forward, then backward)\n",
        "    exog_cols_to_fill = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "    for col in exog_cols_to_fill:\n",
        "        df[col] = df.groupby('Store')[col].transform(lambda x: x.ffill().bfill())\n",
        "        test_df[col] = test_df.groupby('Store')[col].transform(lambda x: x.ffill().bfill())\n",
        "\n",
        "    # 4. Formatting for Time Series Models\n",
        "    df['ds'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # DIAGNOSTIC 1: Check target before renaming\n",
        "    if 'Weekly_Sales' not in df.columns:\n",
        "        print(f\"CRITICAL ERROR: 'Weekly_Sales' column not found. Available columns: {df.columns.tolist()}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    df = df.rename(columns={'Weekly_Sales': 'y'})\n",
        "    df['unique_id'] = df['Store'].astype(str) + '_' + df['Dept'].astype(str)\n",
        "\n",
        "    test_df['ds'] = pd.to_datetime(test_df['Date'])\n",
        "    test_df['unique_id'] = test_df['Store'].astype(str) + '_' + test_df['Dept'].astype(str)\n",
        "\n",
        "    # 5. Downsample: Select Top 20 series by volume\n",
        "    top_series = df.groupby('unique_id')['y'].sum().nlargest(20).index\n",
        "    df_subset = df[df['unique_id'].isin(top_series)].reset_index(drop=True)\n",
        "    test_subset = test_df[test_df['unique_id'].isin(top_series)].reset_index(drop=True)\n",
        "\n",
        "    # 6. Feature Engineering (Encodings)\n",
        "    df_subset['IsHoliday'] = df_subset['IsHoliday'].astype(int)\n",
        "    df_subset['Type'] = df_subset['Type'].map({'A': 1, 'B': 2, 'C': 3})\n",
        "    test_subset['IsHoliday'] = test_subset['IsHoliday'].astype(int)\n",
        "    test_subset['Type'] = test_subset['Type'].map({'A': 1, 'B': 2, 'C': 3})\n",
        "\n",
        "    # Ensure continuous date ranges for each unique_id in training data\n",
        "    all_series_dfs_train = []\n",
        "    for uid in df_subset['unique_id'].unique():\n",
        "        series_df = df_subset[df_subset['unique_id'] == uid].copy()\n",
        "        min_ds = series_df['ds'].min()\n",
        "        max_ds = series_df['ds'].max()\n",
        "\n",
        "        # This aligns the generated timeline with the Walmart Friday dates\n",
        "        full_date_range = pd.date_range(start=min_ds, end=max_ds, freq='W-FRI')\n",
        "\n",
        "\n",
        "        full_series_df = pd.DataFrame({'ds': full_date_range, 'unique_id': uid})\n",
        "\n",
        "        # Merge back with original series data\n",
        "        series_df = full_series_df.merge(series_df, on=['unique_id', 'ds'], how='left')\n",
        "        all_series_dfs_train.append(series_df)\n",
        "\n",
        "    df_subset = pd.concat(all_series_dfs_train).reset_index(drop=True)\n",
        "\n",
        "    # Final Safety Check: Ensure no NaNs remain in features used for ML\n",
        "    exogenous_ml_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
        "                         'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5',\n",
        "                         'IsHoliday', 'Type', 'Size']\n",
        "\n",
        "    # Fill any remaining NaNs (e.g., from reindexing or initial missing data) with 0\n",
        "    df_subset['y'] = df_subset['y'].fillna(0)\n",
        "    df_subset[exogenous_ml_cols] = df_subset[exogenous_ml_cols].fillna(0)\n",
        "    test_subset[exogenous_ml_cols] = test_subset[exogenous_ml_cols].fillna(0)\n",
        "\n",
        "    # Drop the original 'Date' column\n",
        "    df_subset = df_subset.drop(columns=['Date'], errors='ignore')\n",
        "    test_subset = test_subset.drop(columns=['Date'], errors='ignore')\n",
        "\n",
        "    #  DIAGNOSTIC 2: Verify Sales Sum\n",
        "    print(\"\\n--- DIAGNOSTIC CHECK ---\")\n",
        "    if 'y' in df_subset.columns:\n",
        "        total_y = df_subset['y'].sum()\n",
        "        print(f\"Total Sum of 'y' (Sales): {total_y:,.2f}\")\n",
        "\n",
        "        if total_y == 0:\n",
        "            print(\"CRITICAL ERROR: 'y' still contains only 0s.\")\n",
        "            return None, None\n",
        "        else:\n",
        "            print(\"STATUS: Data verified. Sales column 'y' is populated.\")\n",
        "    else:\n",
        "        print(\"CRITICAL ERROR: 'y' column disappeared.\")\n",
        "        return None, None\n",
        "    print(\"------------------------\\n\")\n",
        "\n",
        "\n",
        "    print(f\"Data Prepared. Modeling {df_subset['unique_id'].nunique()} series.\")\n",
        "    return df_subset, test_subset\n",
        "\n",
        "# EXECUTE THE FUNCTION\n",
        "train_subset, test_subset = load_and_prep_data()\n",
        "\n",
        "# Verify results\n",
        "if train_subset is not None and test_subset is not None:\n",
        "    print(\"\\nSuccess! First 5 rows of testing data:\")\n",
        "    print(test_subset.head())\n",
        "else:\n",
        "    print(\"Error: Data loading and preparation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJIq0XcO340-",
        "outputId": "f6c04aa6-b48b-4e9d-abcc-25f88b8d07e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. TimeGPT Pipeline\n",
        "\n",
        "from nixtla import NixtlaClient\n",
        "import pandas as pd\n",
        "\n",
        "def run_timegpt_pipeline(df_train, df_test, horizon, n_windows):\n",
        "    print(\"\\n--- Running TimeGPT ---\")\n",
        "\n",
        "    # 1. API KEY\n",
        "\n",
        "    my_api_key = 'nixak-eX92lSIatoWxvaVDNG4v7IFJQ5cva8FrMRaNuADzsiAlt007Tm8ejGc7VUU0MJEt2YZtsa2CmsfcbYPg'\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Initialize the client\n",
        "        nixtla_client = NixtlaClient(api_key=my_api_key)\n",
        "\n",
        "        # Validates the key before running heavy tasks\n",
        "        nixtla_client.validate_api_key()\n",
        "\n",
        "        # A. Cross-Validation\n",
        "        # We use 'W-FRI' because the data ends on Fridays\n",
        "        print(\"  Running TimeGPT Cross-Validation...\")\n",
        "        timegpt_cv = nixtla_client.cross_validation(\n",
        "            df=df_train,\n",
        "            h=horizon,\n",
        "            n_windows=n_windows,\n",
        "            step_size=horizon,\n",
        "            freq='W-FRI'\n",
        "        )\n",
        "\n",
        "        # B. Future Forecast\n",
        "        # Prepare future exogenous variables (Test set without the target 'y')\n",
        "        future_exog = df_test.drop(columns=['Date', 'Weekly_Sales', 'y'], errors='ignore')\n",
        "\n",
        "        # Calculate horizon based on test set length (should be 39 weeks for this dataset)\n",
        "        test_horizon = df_test.groupby('unique_id')['ds'].count().max()\n",
        "\n",
        "        print(f\"  Running TimeGPT Future Forecast ({test_horizon} weeks)...\")\n",
        "        timegpt_fcst = nixtla_client.forecast(\n",
        "            df=df_train,\n",
        "            h=test_horizon,\n",
        "            X_df=future_exog,\n",
        "            freq='W-FRI'\n",
        "        )\n",
        "\n",
        "        return timegpt_cv, timegpt_fcst\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running TimeGPT: {e}\")\n",
        "        print(\"TIP: Check if your API key is pasted correctly inside the quotes.\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "# EXECUTE THE FUNCTION\n",
        "if 'train_subset' in globals() and 'test_subset' in globals():\n",
        "    # Run pipeline\n",
        "    tgpt_cv, tgpt_fcst = run_timegpt_pipeline(train_subset, test_subset, horizon=4, n_windows=5)\n",
        "\n",
        "    # Print results if successful\n",
        "    if not tgpt_cv.empty:\n",
        "        print(\"\\nSuccess! TimeGPT Cross-Validation Head:\")\n",
        "        print(tgpt_cv.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2bde3429839241c78b56644d387f00d8",
            "cc25f337b0c0499baa683f80fcaab583",
            "a112c8827a5d4fbca42d0e7eed3c73c7",
            "2209404beb6840a79cf0e4ca1640eadf",
            "fbc59f91b6df49cc9163c5cc6b3be16e",
            "79a1e0e5a458433985cc96d6332abc7c",
            "165bba3b67174d3a8e9cf02d0420a0d3",
            "776a083e13504f6b80bbf0908cec4d40"
          ]
        },
        "id": "NkYMg1Gy69Dz",
        "outputId": "6e475cc3-8537-487a-ef7d-fd6c7795d4f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 4. Standard Models Pipeline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "\n",
        "# Set pandas to show all columns (so you can see all models)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "def run_standard_pipeline(df):\n",
        "    HORIZON = 4\n",
        "    N_WINDOWS = 5\n",
        "    FREQ = 'W-FRI'\n",
        "\n",
        "    # A. StatsForecast (Naive, ARIMA, ETS)\n",
        "    print(f\"[{'StatsForecast':<15}] Training: Naive, SeasonalNaive, AutoETS, AutoARIMA\")\n",
        "    sf = StatsForecast(\n",
        "        models=[\n",
        "            Naive(),\n",
        "            SeasonalNaive(season_length=52),\n",
        "            AutoETS(season_length=52),\n",
        "            AutoARIMA(season_length=52)\n",
        "        ],\n",
        "        freq=FREQ,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    stats_cv = sf.cross_validation(\n",
        "        df=df[['unique_id', 'ds', 'y']],\n",
        "        h=HORIZON, step_size=HORIZON, n_windows=N_WINDOWS\n",
        "    )\n",
        "\n",
        "    # B. MLForecast (LightGBM)\n",
        "    print(f\"[{'MLForecast':<15}] Training: LightGBM\")\n",
        "    lgbm = LGBMRegressor(verbosity=-1, random_state=42)\n",
        "\n",
        "    # Prepare features\n",
        "    mlforecast_cols = [\n",
        "        'unique_id', 'ds', 'y', 'Type', 'Size',\n",
        "        'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
        "        'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5',\n",
        "        'IsHoliday'\n",
        "    ]\n",
        "    df_for_mlforecast = df[mlforecast_cols].copy()\n",
        "\n",
        "    mlf = MLForecast(\n",
        "        models=[lgbm], freq=FREQ, lags=[1, 4, 52],\n",
        "        target_transforms=[Differences([1])],\n",
        "        date_features=['month', 'week'], num_threads=4\n",
        "    )\n",
        "\n",
        "    ml_cv = mlf.cross_validation(\n",
        "        df=df_for_mlforecast,\n",
        "        h=HORIZON, step_size=HORIZON, n_windows=N_WINDOWS,\n",
        "        static_features=['Type', 'Size']\n",
        "    )\n",
        "    ml_cv = ml_cv.rename(columns={'LGBMRegressor': 'LightGBM'})\n",
        "\n",
        "    # C. NeuralForecast (AutoNBEATS, AutoNHITS)\n",
        "    print(f\"[{'NeuralForecast':<15}] Training: AutoNBEATS, AutoNHITS\")\n",
        "\n",
        "    nf = NeuralForecast(\n",
        "        models=[\n",
        "            AutoNBEATS(h=HORIZON, num_samples=2),\n",
        "            AutoNHITS(h=HORIZON, num_samples=2)\n",
        "        ],\n",
        "        freq=FREQ\n",
        "    )\n",
        "\n",
        "    neural_cv = nf.cross_validation(\n",
        "        df=df[['unique_id', 'ds', 'y']],\n",
        "        val_size=HORIZON,\n",
        "        n_windows=N_WINDOWS,\n",
        "        step_size=HORIZON\n",
        "    )\n",
        "\n",
        "    # D. MERGING ALL RESULTS\n",
        "    print(\"Merging all model predictions...\")\n",
        "\n",
        "    # Start with StatsForecast\n",
        "    all_results = stats_cv.copy()\n",
        "\n",
        "    # Merge MLForecast (dropping 'y' to avoid duplication)\n",
        "    if ml_cv is not None:\n",
        "        all_results = all_results.merge(\n",
        "            ml_cv.drop(columns=['y'], errors='ignore'),\n",
        "            on=['unique_id', 'ds', 'cutoff'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    # Merge NeuralForecast (dropping 'y' to avoid duplication)\n",
        "    if neural_cv is not None:\n",
        "        all_results = all_results.merge(\n",
        "            neural_cv.drop(columns=['y'], errors='ignore'),\n",
        "            on=['unique_id', 'ds', 'cutoff'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# EXECUTE\n",
        "if 'train_subset' in globals():\n",
        "    # Filter for active data\n",
        "    active_ids = train_subset.groupby('unique_id')['y'].sum()\n",
        "    active_ids = active_ids[active_ids > 0].index.tolist()\n",
        "\n",
        "    if len(active_ids) > 0:\n",
        "        train_subset_clean = train_subset[train_subset['unique_id'].isin(active_ids)].copy()\n",
        "\n",
        "        # Run Pipeline\n",
        "        combined_results = run_standard_pipeline(train_subset_clean)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SUCCESS! PREDICTIONS FROM ALL MODELS:\")\n",
        "        print(\"=\"*50)\n",
        "        print(combined_results.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5a9ec4a5dc4438fbfa016c0bbe2b381",
            "05e2d6ed75a44cd182844c4157338d13",
            "82c46e1be0ab447680d10b54c5d7330e",
            "8753ed44ab8d44ef91b20aee07d956dd",
            "419e618396394b00b1121c27211b8cd7",
            "41bd11b37cf04e1196cf4e91a80526b9",
            "02bcd606cc9b4ecba90dc9143e328a25",
            "cafa1134b4ef4b32a87348eb02475020"
          ]
        },
        "id": "ASbJMUvw7GZQ",
        "outputId": "5c603b8d-52e5-4449-f2dd-206557d8bda7"
      },
      "outputs": [],
      "source": [
        "# 5. Generate Testing Outputs (Final Corrected Version)\n",
        "\n",
        "import pandas as pd\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "from neuralforecast.losses.pytorch import MAE  # Import MAE for stability\n",
        "\n",
        "def generate_future_forecasts(df_train, df_test):\n",
        "    print(\"\\n--- Generating Future Forecasts (Testing Outputs) ---\")\n",
        "\n",
        "    # 1. Configuration\n",
        "    FREQ = 'W-FRI'\n",
        "    # Calculate horizon based on the test set\n",
        "    HORIZON = df_test.groupby('unique_id')['ds'].count().max()\n",
        "    print(f\"Forecasting horizon: {HORIZON} weeks\")\n",
        "\n",
        "    # 2. StatsForecast\n",
        "    print(\"1. Generating StatsForecast predictions...\")\n",
        "    sf = StatsForecast(\n",
        "        models=[\n",
        "            Naive(),\n",
        "            SeasonalNaive(season_length=52),\n",
        "            AutoETS(season_length=52),\n",
        "            AutoARIMA(season_length=52)\n",
        "        ],\n",
        "        freq=FREQ,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    sf_fut = sf.forecast(df=df_train[['unique_id', 'ds', 'y']], h=HORIZON)\n",
        "    sf_fut = sf_fut.reset_index()\n",
        "\n",
        "    # 3. MLForecast (LightGBM)\n",
        "    print(\"2. Generating MLForecast (LightGBM) predictions...\")\n",
        "    lgbm = LGBMRegressor(verbosity=-1, random_state=42)\n",
        "\n",
        "    mlf = MLForecast(\n",
        "        models=[lgbm],\n",
        "        freq=FREQ,\n",
        "        lags=[1, 4, 52],\n",
        "        target_transforms=[Differences([1])],\n",
        "        date_features=['month', 'week'],\n",
        "        num_threads=4\n",
        "    )\n",
        "\n",
        "    # Define columns\n",
        "    ml_train_cols = ['unique_id', 'ds', 'y', 'Type', 'Size', 'Temperature',\n",
        "                     'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday',\n",
        "                     'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "\n",
        "    # Fit (Defining Type and Size as static)\n",
        "    mlf.fit(df=df_train[ml_train_cols], static_features=['Type', 'Size'])\n",
        "\n",
        "    # The model already knows 'Type' and 'Size' from training.\n",
        "    cols_to_drop = ['y', 'Weekly_Sales', 'Type', 'Size']\n",
        "    X_df_future = df_test.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    ml_fut = mlf.predict(h=HORIZON, X_df=X_df_future)\n",
        "    ml_fut = ml_fut.rename(columns={'LGBMRegressor': 'LightGBM'})\n",
        "\n",
        "    # 4. NeuralForecast (Auto Models Stabilized)\n",
        "    print(\"3. Generating NeuralForecast predictions...\")\n",
        "\n",
        "    # STABILITY SETTINGS:\n",
        "    nf = NeuralForecast(\n",
        "        models=[\n",
        "            AutoNBEATS(\n",
        "                h=HORIZON,\n",
        "                loss=MAE(),\n",
        "                num_samples=5\n",
        "            ),\n",
        "            AutoNHITS(\n",
        "                h=HORIZON,\n",
        "                loss=MAE(),\n",
        "                num_samples=5\n",
        "            )\n",
        "        ],\n",
        "        freq=FREQ\n",
        "    )\n",
        "\n",
        "    nf.fit(df=df_train[['unique_id', 'ds', 'y']])\n",
        "    nf_fut = nf.predict(futr_df=df_test[['unique_id', 'ds']])\n",
        "\n",
        "    # 5. Merge All Results\n",
        "    print(\"Merging future forecasts...\")\n",
        "    final_fut = sf_fut.copy()\n",
        "    final_fut = final_fut.merge(ml_fut, on=['unique_id', 'ds'], how='left')\n",
        "    final_fut = final_fut.merge(nf_fut, on=['unique_id', 'ds'], how='left')\n",
        "\n",
        "    return final_fut\n",
        "\n",
        "# EXECUTE\n",
        "# FIXED CONDITION: Checks if variable exists AND is not None\n",
        "if ('train_subset' in globals() and train_subset is not None) and \\\n",
        "   ('test_subset' in globals() and test_subset is not None):\n",
        "\n",
        "    print(\"Data found. Proceeding with forecast generation...\")\n",
        "\n",
        "    # Filter for active data to ensure stability\n",
        "    active_ids = train_subset.groupby('unique_id')['y'].sum()\n",
        "    active_ids = active_ids[active_ids > 0].index.tolist()\n",
        "    train_clean = train_subset[train_subset['unique_id'].isin(active_ids)].copy()\n",
        "    test_clean = test_subset[test_subset['unique_id'].isin(active_ids)].copy()\n",
        "\n",
        "    # RUN FUNCTION\n",
        "    future_forecasts = generate_future_forecasts(train_clean, test_clean)\n",
        "\n",
        "    # MERGE TIMEGPT IF AVAILABLE\n",
        "    if 'tgpt_fcst' in globals() and tgpt_fcst is not None and not tgpt_fcst.empty:\n",
        "        print(\"Merging TimeGPT results...\")\n",
        "        cols_to_merge = ['unique_id', 'ds', 'TimeGPT']\n",
        "        if all(col in tgpt_fcst.columns for col in cols_to_merge):\n",
        "             future_forecasts = future_forecasts.merge(\n",
        "                 tgpt_fcst[cols_to_merge],\n",
        "                 on=['unique_id', 'ds'],\n",
        "                 how='left'\n",
        "             )\n",
        "\n",
        "    print(\"\\nSuccess! Future forecasts generated.\")\n",
        "    print(future_forecasts.head())\n",
        "\n",
        "else:\n",
        "    print(\"Error: 'train_subset' or 'test_subset' are None or missing.\")\n",
        "    print(\"Please go back and re-run Step 2 (Data Loading) to ensure the DataFrames are created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQj1yszz7aqa",
        "outputId": "6ef0b2df-ecf5-47c5-84b9-abcfa29b71ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Evaluation Metrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def calculate_metrics(cv_df):\n",
        "    # Identify model columns (exclude ID/Date/Target columns)\n",
        "    models = [c for c in cv_df.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "    results = []\n",
        "\n",
        "    for model in models:\n",
        "        y_true = cv_df['y']\n",
        "        y_pred = cv_df[model]\n",
        "\n",
        "        # Drop NaNs for metric calculation (in case of alignment issues)\n",
        "        valid_mask = ~np.isnan(y_pred)\n",
        "        y_true_clean = y_true[valid_mask]\n",
        "        y_pred_clean = y_pred[valid_mask]\n",
        "\n",
        "        if len(y_true_clean) == 0:\n",
        "            continue\n",
        "\n",
        "        # Rubric Metrics\n",
        "        me = np.mean(y_true_clean - y_pred_clean)\n",
        "        mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "\n",
        "        # MAPE (handling zeros)\n",
        "        mask = y_true_clean != 0\n",
        "        if mask.any():\n",
        "            mape = np.mean(np.abs((y_true_clean[mask] - y_pred_clean[mask]) / y_true_clean[mask])) * 100\n",
        "        else:\n",
        "            mape = np.nan\n",
        "\n",
        "        results.append({'Model': model, 'ME': me, 'MAE': mae, 'RMSE': rmse, 'MAPE': mape})\n",
        "\n",
        "    return pd.DataFrame(results).sort_values(by='RMSE')\n",
        "\n",
        "def count_winners(cv_df):\n",
        "    models = [c for c in cv_df.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "    errors = cv_df.copy()\n",
        "\n",
        "    # Calculate absolute error for every row\n",
        "    for m in models:\n",
        "        errors[m] = (errors['y'] - errors[m]).abs()\n",
        "\n",
        "    # Find model with lowest MAE per series\n",
        "    series_mae = errors.groupby('unique_id')[models].mean()\n",
        "    series_mae['Winner'] = series_mae.idxmin(axis=1)\n",
        "\n",
        "    return series_mae['Winner'].value_counts().reset_index()\n",
        "\n",
        "# EXECUTE THE FUNCTIONS\n",
        "# We look for 'combined_results' which comes from Step 4 (The Cross-Validation Step)\n",
        "if 'combined_results' in globals():\n",
        "    print(\"\\n--- Calculating Global Accuracy Metrics ---\")\n",
        "    metrics_df = calculate_metrics(combined_results)\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\n--- Model Leaderboard (Wins per Series) ---\")\n",
        "    winners_df = count_winners(combined_results)\n",
        "    print(winners_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "V_IOb0Mr7lBq",
        "outputId": "53b6961c-875c-48cc-d6ba-9082c0c1a1a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 7. Main Execution (Corrected for Unified Pipeline)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Check if functions from previous cells are defined\n",
        "required_funcs = ['load_and_prep_data', 'run_standard_pipeline', 'run_timegpt_pipeline',\n",
        "                  'generate_future_forecasts', 'calculate_metrics', 'count_winners']\n",
        "\n",
        "if not all(func in globals() for func in required_funcs):\n",
        "    print(\"Error: Required functions are missing.\")\n",
        "    print(\"Please make sure you have run ALL previous cells (Steps 2-6) before running this one.\")\n",
        "else:\n",
        "    print(\"Starting Main Execution Pipeline...\\n\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    train_subset, test_subset = load_and_prep_data()\n",
        "\n",
        "    if train_subset is not None:\n",
        "        # 2. Run Standard Model\n",
        "        final_eval = run_standard_pipeline(train_subset)\n",
        "\n",
        "        # 3. Run TimeGPT (Remote)\n",
        "        tgpt_cv, tgpt_fcst = run_timegpt_pipeline(train_subset, test_subset, horizon=4, n_windows=5)\n",
        "\n",
        "        # 4. Merge TimeGPT into Evaluation Results\n",
        "        print(\"Merging TimeGPT results...\")\n",
        "        merge_keys = ['unique_id', 'ds', 'cutoff']\n",
        "\n",
        "        if not tgpt_cv.empty and 'TimeGPT' in tgpt_cv.columns:\n",
        "            # Drop 'y' from TimeGPT CV to avoid duplicates if it exists\n",
        "            tgpt_clean = tgpt_cv.drop(columns=['y'], errors='ignore')\n",
        "            final_eval = final_eval.merge(tgpt_clean, on=merge_keys, how='left')\n",
        "\n",
        "        # 5. Generate Future Forecasts\n",
        "        future_forecasts = generate_future_forecasts(train_subset, test_subset)\n",
        "\n",
        "        # Merge TimeGPT Future Forecasts if available\n",
        "        if not tgpt_fcst.empty and 'TimeGPT' in tgpt_fcst.columns:\n",
        "             future_forecasts = future_forecasts.merge(\n",
        "                 tgpt_fcst[['unique_id', 'ds', 'TimeGPT']],\n",
        "                 on=['unique_id', 'ds'],\n",
        "                 how='left'\n",
        "             )\n",
        "\n",
        "        # 6. Metrics & Winners\n",
        "        metrics_df = calculate_metrics(final_eval)\n",
        "        winners_df = count_winners(final_eval)\n",
        "\n",
        "        print(\"\\n--- Final Metrics ---\")\n",
        "        print(metrics_df)\n",
        "        print(\"\\n--- Model Winners (Count by Series) ---\")\n",
        "        print(winners_df)\n",
        "\n",
        "        # 7. Save CSVs\n",
        "        final_eval.to_csv('final_evaluation_output.csv', index=False)\n",
        "        metrics_df.to_csv('final_metrics_summary.csv', index=False)\n",
        "        future_forecasts.to_csv('testing_outputs.csv', index=False)\n",
        "        print(\"\\n Files Saved: final_evaluation_output.csv, final_metrics_summary.csv, testing_outputs.csv\")\n",
        "\n",
        "        # 8. Plotting\n",
        "        # Check if we have data to plot\n",
        "        if not final_eval.empty:\n",
        "            u_id = final_eval['unique_id'].unique()[0]\n",
        "            subset = final_eval[final_eval['unique_id'] == u_id]\n",
        "\n",
        "            plt.figure(figsize=(14, 6))\n",
        "\n",
        "            # Plot Actuals\n",
        "            if 'y' in subset.columns:\n",
        "                plt.plot(subset['ds'], subset['y'], label='Actual', color='black', linewidth=2)\n",
        "\n",
        "            # Plot models dynamically\n",
        "            plot_models = [c for c in subset.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "            for m in plot_models:\n",
        "                # Plot only if column is numeric\n",
        "                if pd.api.types.is_numeric_dtype(subset[m]):\n",
        "                    plt.plot(subset['ds'], subset[m], label=m, alpha=0.7)\n",
        "\n",
        "            plt.title(f\"Forecast Models vs Actual: {u_id}\")\n",
        "            plt.legend()\n",
        "            plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02bcd606cc9b4ecba90dc9143e328a25": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cafa1134b4ef4b32a87348eb02475020",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "05e2d6ed75a44cd182844c4157338d13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165bba3b67174d3a8e9cf02d0420a0d3": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_776a083e13504f6b80bbf0908cec4d40",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "2209404beb6840a79cf0e4ca1640eadf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bde3429839241c78b56644d387f00d8": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cc25f337b0c0499baa683f80fcaab583",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 999/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 11.000 train_loss_step: 0.086</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.104             </span>\n</pre>\n",
                  "text/plain": "Epoch 999/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 11.000 train_loss_step: 0.086\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.104             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "419e618396394b00b1121c27211b8cd7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_41bd11b37cf04e1196cf4e91a80526b9",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "41bd11b37cf04e1196cf4e91a80526b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776a083e13504f6b80bbf0908cec4d40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a1e0e5a458433985cc96d6332abc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c46e1be0ab447680d10b54c5d7330e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8753ed44ab8d44ef91b20aee07d956dd",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 799/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 16.000 train_loss_step:      </span>\n                                                                               <span style=\"font-style: italic\">1335.244 train_loss_epoch: 1343.614 </span>\n</pre>\n",
                  "text/plain": "Epoch 799/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 16.000 train_loss_step:      \u001b[0m\n                                                                               \u001b[3m1335.244 train_loss_epoch: 1343.614 \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "8753ed44ab8d44ef91b20aee07d956dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a112c8827a5d4fbca42d0e7eed3c73c7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2209404beb6840a79cf0e4ca1640eadf",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "cafa1134b4ef4b32a87348eb02475020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc25f337b0c0499baa683f80fcaab583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a9ec4a5dc4438fbfa016c0bbe2b381": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_05e2d6ed75a44cd182844c4157338d13",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 999/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 15.000 train_loss_step: 0.072</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.072             </span>\n</pre>\n",
                  "text/plain": "Epoch 999/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 15.000 train_loss_step: 0.072\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.072             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "fbc59f91b6df49cc9163c5cc6b3be16e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79a1e0e5a458433985cc96d6332abc7c",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 499/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 13.000 train_loss_step: 0.024</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.029             </span>\n</pre>\n",
                  "text/plain": "Epoch 499/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 13.000 train_loss_step: 0.024\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.029             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
