{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuU6bC1D0qzq",
        "outputId": "8da3eb02-ecb6-4c2c-f9c9-59d81de9e133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: statsforecast in /usr/local/lib/python3.12/dist-packages (2.0.3)\n",
            "Requirement already satisfied: mlforecast in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: neuralforecast in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: nixtla in /usr/local/lib/python3.12/dist-packages (0.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from statsforecast) (3.1.2)\n",
            "Requirement already satisfied: coreforecast>=0.0.12 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (0.0.16)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (0.60.0)\n",
            "Requirement already satisfied: scipy<1.16.0,>=1.7.3 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from statsforecast) (4.67.1)\n",
            "Requirement already satisfied: fugue>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (0.9.3)\n",
            "Requirement already satisfied: utilsforecast>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (0.2.15)\n",
            "Requirement already satisfied: threadpoolctl>=3 in /usr/local/lib/python3.12/dist-packages (from statsforecast) (3.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from mlforecast) (2025.3.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from mlforecast) (4.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from mlforecast) (1.6.1)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from neuralforecast) (2.9.0+cu126)\n",
            "Requirement already satisfied: pytorch-lightning>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from neuralforecast) (2.6.0)\n",
            "Requirement already satisfied: ray>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.52.1)\n",
            "Requirement already satisfied: annotated-types in /usr/local/lib/python3.12/dist-packages (from nixtla) (0.7.0)\n",
            "Requirement already satisfied: httpx[zstd] in /usr/local/lib/python3.12/dist-packages (from nixtla) (0.28.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from nixtla) (3.11.4)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.12/dist-packages (from nixtla) (2.12.3)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from nixtla) (9.1.2)\n",
            "Requirement already satisfied: triad>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from fugue>=0.8.1->statsforecast) (1.0.0)\n",
            "Requirement already satisfied: adagio>=0.2.6 in /usr/local/lib/python3.12/dist-packages (from fugue>=0.8.1->statsforecast) (0.2.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.55.0->statsforecast) (0.43.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nixtla) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nixtla) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10->nixtla) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.3)\n",
            "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.8.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.15.2)\n",
            "Requirement already satisfied: click!=8.3.*,>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (8.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (5.29.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2.32.4)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.12/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.4)\n",
            "Requirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (18.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->neuralforecast) (3.5.0)\n",
            "Requirement already satisfied: narwhals>=2.0 in /usr/local/lib/python3.12/dist-packages (from utilsforecast>=0.1.4->statsforecast) (2.12.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[zstd]->nixtla) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[zstd]->nixtla) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[zstd]->nixtla) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[zstd]->nixtla) (3.11)\n",
            "Requirement already satisfied: zstandard>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from httpx[zstd]->nixtla) (0.25.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[zstd]->nixtla) (0.16.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast) (6.10.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast) (2.0.44)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->mlforecast) (1.5.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast) (1.3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (3.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->neuralforecast) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[zstd]->nixtla) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->neuralforecast) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.29.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.22.0)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. Installation & Imports\n",
        "# ==========================================\n",
        "!pip install pandas numpy matplotlib seaborn statsforecast mlforecast neuralforecast lightgbm nixtla\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# StatsForecast\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "\n",
        "# MLForecast\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# NeuralForecast\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "\n",
        "# TimeGPT\n",
        "from nixtla import NixtlaClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3YjoYo83cd9",
        "outputId": "92193add-1ecc-4d59-f971-48a950bf97b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "\n",
            "--- DIAGNOSTIC CHECK ---\n",
            "Total Sum of 'y' (Sales): 402,568,823.37\n",
            "STATUS: Data verified. Sales column 'y' is populated.\n",
            "------------------------\n",
            "\n",
            "Data Prepared. Modeling 20 series.\n",
            "\n",
            "Success! First 5 rows of testing data:\n",
            "   Store  Dept  IsHoliday  Type    Size  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment         ds unique_id\n",
            "0      1    92          0     1  151315        55.32       3.386    6766.44    5147.70      50.82    3639.90    2737.42  223.462779         6.573 2012-11-02      1_92\n",
            "1      1    92          0     1  151315        61.24       3.314   11421.32    3370.89      40.28    4646.79    6154.16  223.481307         6.573 2012-11-09      1_92\n",
            "2      1    92          0     1  151315        52.92       3.252    9696.28     292.10     103.78    1133.15    6612.69  223.512911         6.573 2012-11-16      1_92\n",
            "3      1    92          1     1  151315        56.23       3.211     883.59       4.17   74910.32     209.91     303.32  223.561947         6.573 2012-11-23      1_92\n",
            "4      1    92          0     1  151315        52.34       3.207    2460.03       0.00    3838.35     150.57    6966.34  223.610984         6.573 2012-11-30      1_92\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 2. Data Loading & Preprocessing (Fixed Date Frequency)\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_and_prep_data():\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    # 1. Load CSVs\n",
        "    try:\n",
        "        train = pd.read_csv('train.csv')\n",
        "        features = pd.read_csv('features.csv')\n",
        "        test = pd.read_csv('test.csv')\n",
        "        stores = pd.read_csv('stores.csv')\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error finding file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # 2. Merge Dataframes\n",
        "    # Merge Store metadata and Features into Train\n",
        "    df = train.merge(stores, on='Store', how='left')\n",
        "    df = df.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "    # Merge Test data as well\n",
        "    test_df = test.merge(stores, on='Store', how='left')\n",
        "    test_df = test_df.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
        "\n",
        "    # 3. Handle Missing Values\n",
        "    # Markdowns: Fill with 0 (missing markdown = no promotion)\n",
        "    md_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "    df[md_cols] = df[md_cols].fillna(0)\n",
        "    test_df[md_cols] = test_df[md_cols].fillna(0)\n",
        "\n",
        "    # Economic Indicators: Interpolate (Fill forward, then backward)\n",
        "    exog_cols_to_fill = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "    for col in exog_cols_to_fill:\n",
        "        df[col] = df.groupby('Store')[col].transform(lambda x: x.ffill().bfill())\n",
        "        test_df[col] = test_df.groupby('Store')[col].transform(lambda x: x.ffill().bfill())\n",
        "\n",
        "    # 4. Formatting for Time Series Models\n",
        "    df['ds'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # DIAGNOSTIC 1: Check target before renaming\n",
        "    if 'Weekly_Sales' not in df.columns:\n",
        "        print(f\"CRITICAL ERROR: 'Weekly_Sales' column not found. Available columns: {df.columns.tolist()}\")\n",
        "        return None, None\n",
        "    # --------------------------------------------------\n",
        "\n",
        "    df = df.rename(columns={'Weekly_Sales': 'y'})\n",
        "    df['unique_id'] = df['Store'].astype(str) + '_' + df['Dept'].astype(str)\n",
        "\n",
        "    test_df['ds'] = pd.to_datetime(test_df['Date'])\n",
        "    test_df['unique_id'] = test_df['Store'].astype(str) + '_' + test_df['Dept'].astype(str)\n",
        "\n",
        "    # 5. Downsample: Select Top 20 series by volume\n",
        "    top_series = df.groupby('unique_id')['y'].sum().nlargest(20).index\n",
        "    df_subset = df[df['unique_id'].isin(top_series)].reset_index(drop=True)\n",
        "    test_subset = test_df[test_df['unique_id'].isin(top_series)].reset_index(drop=True)\n",
        "\n",
        "    # 6. Feature Engineering (Encodings)\n",
        "    df_subset['IsHoliday'] = df_subset['IsHoliday'].astype(int)\n",
        "    df_subset['Type'] = df_subset['Type'].map({'A': 1, 'B': 2, 'C': 3})\n",
        "    test_subset['IsHoliday'] = test_subset['IsHoliday'].astype(int)\n",
        "    test_subset['Type'] = test_subset['Type'].map({'A': 1, 'B': 2, 'C': 3})\n",
        "\n",
        "    # Ensure continuous date ranges for each unique_id in training data\n",
        "    all_series_dfs_train = []\n",
        "    for uid in df_subset['unique_id'].unique():\n",
        "        series_df = df_subset[df_subset['unique_id'] == uid].copy()\n",
        "        min_ds = series_df['ds'].min()\n",
        "        max_ds = series_df['ds'].max()\n",
        "\n",
        "        # This aligns the generated timeline with the Walmart Friday dates\n",
        "        full_date_range = pd.date_range(start=min_ds, end=max_ds, freq='W-FRI')\n",
        "        # ----------------------------------------------------\n",
        "\n",
        "        full_series_df = pd.DataFrame({'ds': full_date_range, 'unique_id': uid})\n",
        "\n",
        "        # Merge back with original series data\n",
        "        series_df = full_series_df.merge(series_df, on=['unique_id', 'ds'], how='left')\n",
        "        all_series_dfs_train.append(series_df)\n",
        "\n",
        "    df_subset = pd.concat(all_series_dfs_train).reset_index(drop=True)\n",
        "\n",
        "    # Final Safety Check: Ensure no NaNs remain in features used for ML\n",
        "    exogenous_ml_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
        "                         'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5',\n",
        "                         'IsHoliday', 'Type', 'Size']\n",
        "\n",
        "    # Fill any remaining NaNs (e.g., from reindexing or initial missing data) with 0\n",
        "    df_subset['y'] = df_subset['y'].fillna(0)\n",
        "    df_subset[exogenous_ml_cols] = df_subset[exogenous_ml_cols].fillna(0)\n",
        "    test_subset[exogenous_ml_cols] = test_subset[exogenous_ml_cols].fillna(0)\n",
        "\n",
        "    # Drop the original 'Date' column\n",
        "    df_subset = df_subset.drop(columns=['Date'], errors='ignore')\n",
        "    test_subset = test_subset.drop(columns=['Date'], errors='ignore')\n",
        "\n",
        "    #  DIAGNOSTIC 2: Verify Sales Sum\n",
        "    print(\"\\n--- DIAGNOSTIC CHECK ---\")\n",
        "    if 'y' in df_subset.columns:\n",
        "        total_y = df_subset['y'].sum()\n",
        "        print(f\"Total Sum of 'y' (Sales): {total_y:,.2f}\")\n",
        "\n",
        "        if total_y == 0:\n",
        "            print(\"CRITICAL ERROR: 'y' still contains only 0s.\")\n",
        "            return None, None\n",
        "        else:\n",
        "            print(\"STATUS: Data verified. Sales column 'y' is populated.\")\n",
        "    else:\n",
        "        print(\"CRITICAL ERROR: 'y' column disappeared.\")\n",
        "        return None, None\n",
        "    print(\"------------------------\\n\")\n",
        "    # ---------------------------------------\n",
        "\n",
        "    print(f\"Data Prepared. Modeling {df_subset['unique_id'].nunique()} series.\")\n",
        "    return df_subset, test_subset\n",
        "\n",
        "# EXECUTE THE FUNCTION\n",
        "train_subset, test_subset = load_and_prep_data()\n",
        "\n",
        "# Verify results\n",
        "if train_subset is not None and test_subset is not None:\n",
        "    print(\"\\nSuccess! First 5 rows of testing data:\")\n",
        "    print(test_subset.head())\n",
        "else:\n",
        "    print(\"Error: Data loading and preparation failed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJIq0XcO340-",
        "outputId": "f6c04aa6-b48b-4e9d-abcc-25f88b8d07e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running TimeGPT ---\n",
            "  Running TimeGPT Cross-Validation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:nixtla.nixtla_client:The specified horizon \"h\" exceeds the model horizon, this may lead to less accurate forecasts. Please consider using a smaller horizon.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Running TimeGPT Future Forecast (39 weeks)...\n",
            "\n",
            "Success! TimeGPT Cross-Validation Head:\n",
            "  unique_id         ds     cutoff          y     TimeGPT\n",
            "0     10_72 2012-06-15 2012-06-08  105499.39  115114.920\n",
            "1     10_72 2012-06-22 2012-06-08  107949.41  181358.220\n",
            "2     10_72 2012-06-29 2012-06-08   96579.10  133881.170\n",
            "3     10_72 2012-07-06 2012-06-08  100464.25  148005.270\n",
            "4     10_72 2012-07-13 2012-07-06   92923.05  113516.984\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 3. TimeGPT Pipeline\n",
        "# ==========================================\n",
        "from nixtla import NixtlaClient\n",
        "import pandas as pd\n",
        "\n",
        "def run_timegpt_pipeline(df_train, df_test, horizon, n_windows):\n",
        "    print(\"\\n--- Running TimeGPT ---\")\n",
        "\n",
        "    # 1. PASTE YOUR API KEY HERE\n",
        "    # ---------------------------------------------------------\n",
        "    my_api_key = 'nixak-eX92lSIatoWxvaVDNG4v7IFJQ5cva8FrMRaNuADzsiAlt007Tm8ejGc7VUU0MJEt2YZtsa2CmsfcbYPg'\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    try:\n",
        "        # Initialize the client\n",
        "        nixtla_client = NixtlaClient(api_key=my_api_key)\n",
        "\n",
        "        # Validates the key before running heavy tasks\n",
        "        nixtla_client.validate_api_key()\n",
        "\n",
        "        # A. Cross-Validation\n",
        "        # We use 'W-FRI' because the data ends on Fridays\n",
        "        print(\"  Running TimeGPT Cross-Validation...\")\n",
        "        timegpt_cv = nixtla_client.cross_validation(\n",
        "            df=df_train,\n",
        "            h=horizon,\n",
        "            n_windows=n_windows,\n",
        "            step_size=horizon,\n",
        "            freq='W-FRI'\n",
        "        )\n",
        "\n",
        "        # B. Future Forecast\n",
        "        # Prepare future exogenous variables (Test set without the target 'y')\n",
        "        future_exog = df_test.drop(columns=['Date', 'Weekly_Sales', 'y'], errors='ignore')\n",
        "\n",
        "        # Calculate horizon based on test set length (should be 39 weeks for this dataset)\n",
        "        test_horizon = df_test.groupby('unique_id')['ds'].count().max()\n",
        "\n",
        "        print(f\"  Running TimeGPT Future Forecast ({test_horizon} weeks)...\")\n",
        "        timegpt_fcst = nixtla_client.forecast(\n",
        "            df=df_train,\n",
        "            h=test_horizon,\n",
        "            X_df=future_exog,\n",
        "            freq='W-FRI'\n",
        "        )\n",
        "\n",
        "        return timegpt_cv, timegpt_fcst\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running TimeGPT: {e}\")\n",
        "        print(\"TIP: Check if your API key is pasted correctly inside the quotes.\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "# EXECUTE THE FUNCTION\n",
        "if 'train_subset' in globals() and 'test_subset' in globals():\n",
        "    # Run pipeline\n",
        "    tgpt_cv, tgpt_fcst = run_timegpt_pipeline(train_subset, test_subset, horizon=4, n_windows=5)\n",
        "\n",
        "    # Print results if successful\n",
        "    if not tgpt_cv.empty:\n",
        "        print(\"\\nSuccess! TimeGPT Cross-Validation Head:\")\n",
        "        print(tgpt_cv.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2bde3429839241c78b56644d387f00d8",
            "cc25f337b0c0499baa683f80fcaab583",
            "a112c8827a5d4fbca42d0e7eed3c73c7",
            "2209404beb6840a79cf0e4ca1640eadf",
            "fbc59f91b6df49cc9163c5cc6b3be16e",
            "79a1e0e5a458433985cc96d6332abc7c",
            "165bba3b67174d3a8e9cf02d0420a0d3",
            "776a083e13504f6b80bbf0908cec4d40"
          ]
        },
        "id": "NkYMg1Gy69Dz",
        "outputId": "6e475cc3-8537-487a-ef7d-fd6c7795d4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[StatsForecast  ] Training: Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
            "[MLForecast     ] Training: LightGBM\n",
            "[NeuralForecast ] Training: AutoNBEATS, AutoNHITS\n",
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2025-12-04_16-35-42   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 2                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2025-12-04_16-35-42\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_16-35-42/_train_tune_2025-12-04_16-35-42/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=26945)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Seed set to 16\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m 2025-12-04 16:36:03.585952: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m E0000 00:00:1764866163.636017   27060 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m E0000 00:00:1764866163.649070   27060 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m W0000 00:00:1764866163.683921   27060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m W0000 00:00:1764866163.683980   27060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m W0000 00:00:1764866163.683984   27060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m W0000 00:00:1764866163.683988   27060 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m 2025-12-04 16:36:03.693968: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=26945)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Trainable params: 2.4 M                                                         \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Non-trainable params: 216                                                       \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Total params: 2.4 M                                                             \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Total estimated model params size (MB): 9                                       \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=26945)\u001b[0m [2025-12-04 16:36:20,930 E 26945 26991] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=26945)\u001b[0m Epoch 999/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m                                                               0.079             \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m                                                               0.079 valid_loss: \n",
            "\u001b[36m(_train_tune pid=26945)\u001b[0m                                                               6234.723          \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=27458)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Seed set to 8\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m 2025-12-04 16:37:58.167212: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m E0000 00:00:1764866278.203734   27602 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m E0000 00:00:1764866278.223518   27602 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m W0000 00:00:1764866278.275374   27602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m W0000 00:00:1764866278.275449   27602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m W0000 00:00:1764866278.275453   27602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m W0000 00:00:1764866278.275455   27602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m 2025-12-04 16:37:58.289276: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=27458)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Trainable params: 2.4 M                                                         \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Non-trainable params: 180                                                       \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Total params: 2.4 M                                                             \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Total estimated model params size (MB): 9                                       \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=27458)\u001b[0m [2025-12-04 16:38:10,369 E 27458 27513] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "2025-12-04 16:39:00,798\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-12-04_16-35-42' in 0.0066s.\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 16\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m Epoch 499/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               2497.830          \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               2497.830          \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               valid_loss:       \n",
            "\u001b[36m(_train_tune pid=27458)\u001b[0m                                                               9802.795          \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 216                                                                                          \n",
              "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 30                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 1                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 216                                                                                          \n",
              "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 30                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 1                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bde3429839241c78b56644d387f00d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a112c8827a5d4fbca42d0e7eed3c73c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2025-12-04_16-40-46   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 2                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2025-12-04_16-40-46\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_16-40-46/_train_tune_2025-12-04_16-40-46/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=28331)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Seed set to 6\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m 2025-12-04 16:41:07.850422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m E0000 00:00:1764866467.919661   28442 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m E0000 00:00:1764866467.939537   28442 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m W0000 00:00:1764866467.993910   28442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m W0000 00:00:1764866467.994000   28442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m W0000 00:00:1764866467.994004   28442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m W0000 00:00:1764866467.994007   28442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m 2025-12-04 16:41:08.010374: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=28331)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Trainable params: 2.4 M                                                         \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Total params: 2.4 M                                                             \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Total estimated model params size (MB): 9                                       \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=28331)\u001b[0m [2025-12-04 16:41:24,690 E 28331 28368] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=28331)\u001b[0m Epoch 1399/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000     \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                train_loss_step: \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                14999268352.000  \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                train_loss_epoch:\n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                14999268352.000  \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                valid_loss:      \n",
            "\u001b[36m(_train_tune pid=28331)\u001b[0m                                                                5894118400.000   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=28331)\u001b[0m `Trainer.fit` stopped: `max_steps=1400.0` reached.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Seed set to 15\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m 2025-12-04 16:43:41.839218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m E0000 00:00:1764866621.866948   29143 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m E0000 00:00:1764866621.874958   29143 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m W0000 00:00:1764866621.904257   29143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m W0000 00:00:1764866621.904317   29143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m W0000 00:00:1764866621.904322   29143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m W0000 00:00:1764866621.904326   29143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m 2025-12-04 16:43:41.914366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=29029)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Trainable params: 2.4 M                                                         \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Total params: 2.4 M                                                             \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Total estimated model params size (MB): 9                                       \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=29029)\u001b[0m [2025-12-04 16:43:59,266 E 29029 29075] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "2025-12-04 16:46:27,223\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-12-04_16-40-46' in 0.0083s.\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 15\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m `Trainer.fit` stopped: `max_steps=500.0` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m Epoch 499/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m                                                               0.024             \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m                                                               0.024 valid_loss: \n",
            "\u001b[36m(_train_tune pid=29029)\u001b[0m                                                               11275.909         \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ blocks       │ ModuleList    │  2.4 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.4 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 2.4 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 33                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 1                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 2.4 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 2.4 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 33                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 1                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbc59f91b6df49cc9163c5cc6b3be16e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=500.0` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "165bba3b67174d3a8e9cf02d0420a0d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging all model predictions...\n",
            "\n",
            "==================================================\n",
            "SUCCESS! PREDICTIONS FROM ALL MODELS:\n",
            "==================================================\n",
            "  unique_id         ds     cutoff          y      Naive  SeasonalNaive        AutoETS      AutoARIMA       LightGBM     AutoNBEATS      AutoNHITS\n",
            "0     10_72 2012-06-15 2012-06-08  105499.39  125434.23      127450.66  125453.077037  135381.194651  145607.035537  144165.359375  128642.929688\n",
            "1     10_72 2012-06-22 2012-06-08  107949.41  125434.23      117948.54  114657.507531  117357.420039  141443.112113  113317.765625  111508.296875\n",
            "2     10_72 2012-06-29 2012-06-08   96579.10  125434.23      114398.47  116075.626160  109978.895935  148534.664866  102078.171875  103085.296875\n",
            "3     10_72 2012-07-06 2012-06-08  100464.25  125434.23      108519.93  109074.835739  102380.377658  149283.028227  116065.226562  113007.320312\n",
            "4     10_72 2012-07-13 2012-07-06   92923.05  100464.25      115004.83  110645.290441  107966.684059  105233.901058  105550.414062  102123.453125\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 4. Standard Models Pipeline\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "\n",
        "# Set pandas to show all columns (so you can see all models)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "def run_standard_pipeline(df):\n",
        "    HORIZON = 4\n",
        "    N_WINDOWS = 5\n",
        "    FREQ = 'W-FRI'\n",
        "\n",
        "    # A. StatsForecast (Naive, ARIMA, ETS)\n",
        "    print(f\"[{'StatsForecast':<15}] Training: Naive, SeasonalNaive, AutoETS, AutoARIMA\")\n",
        "    sf = StatsForecast(\n",
        "        models=[\n",
        "            Naive(),\n",
        "            SeasonalNaive(season_length=52),\n",
        "            AutoETS(season_length=52),\n",
        "            AutoARIMA(season_length=52)\n",
        "        ],\n",
        "        freq=FREQ,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    stats_cv = sf.cross_validation(\n",
        "        df=df[['unique_id', 'ds', 'y']],\n",
        "        h=HORIZON, step_size=HORIZON, n_windows=N_WINDOWS\n",
        "    )\n",
        "\n",
        "    # B. MLForecast (LightGBM)\n",
        "    print(f\"[{'MLForecast':<15}] Training: LightGBM\")\n",
        "    lgbm = LGBMRegressor(verbosity=-1, random_state=42)\n",
        "\n",
        "    # Prepare features\n",
        "    mlforecast_cols = [\n",
        "        'unique_id', 'ds', 'y', 'Type', 'Size',\n",
        "        'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
        "        'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5',\n",
        "        'IsHoliday'\n",
        "    ]\n",
        "    df_for_mlforecast = df[mlforecast_cols].copy()\n",
        "\n",
        "    mlf = MLForecast(\n",
        "        models=[lgbm], freq=FREQ, lags=[1, 4, 52],\n",
        "        target_transforms=[Differences([1])],\n",
        "        date_features=['month', 'week'], num_threads=4\n",
        "    )\n",
        "\n",
        "    ml_cv = mlf.cross_validation(\n",
        "        df=df_for_mlforecast,\n",
        "        h=HORIZON, step_size=HORIZON, n_windows=N_WINDOWS,\n",
        "        static_features=['Type', 'Size']\n",
        "    )\n",
        "    ml_cv = ml_cv.rename(columns={'LGBMRegressor': 'LightGBM'})\n",
        "\n",
        "    # C. NeuralForecast (AutoNBEATS, AutoNHITS)\n",
        "    print(f\"[{'NeuralForecast':<15}] Training: AutoNBEATS, AutoNHITS\")\n",
        "\n",
        "    nf = NeuralForecast(\n",
        "        models=[\n",
        "            AutoNBEATS(h=HORIZON, num_samples=2),\n",
        "            AutoNHITS(h=HORIZON, num_samples=2)\n",
        "        ],\n",
        "        freq=FREQ\n",
        "    )\n",
        "\n",
        "    neural_cv = nf.cross_validation(\n",
        "        df=df[['unique_id', 'ds', 'y']],\n",
        "        val_size=HORIZON,\n",
        "        n_windows=N_WINDOWS,\n",
        "        step_size=HORIZON\n",
        "    )\n",
        "\n",
        "    # D. MERGING ALL RESULTS\n",
        "    print(\"Merging all model predictions...\")\n",
        "\n",
        "    # Start with StatsForecast\n",
        "    all_results = stats_cv.copy()\n",
        "\n",
        "    # Merge MLForecast (dropping 'y' to avoid duplication)\n",
        "    if ml_cv is not None:\n",
        "        all_results = all_results.merge(\n",
        "            ml_cv.drop(columns=['y'], errors='ignore'),\n",
        "            on=['unique_id', 'ds', 'cutoff'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    # Merge NeuralForecast (dropping 'y' to avoid duplication)\n",
        "    if neural_cv is not None:\n",
        "        all_results = all_results.merge(\n",
        "            neural_cv.drop(columns=['y'], errors='ignore'),\n",
        "            on=['unique_id', 'ds', 'cutoff'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# EXECUTE\n",
        "if 'train_subset' in globals():\n",
        "    # Filter for active data\n",
        "    active_ids = train_subset.groupby('unique_id')['y'].sum()\n",
        "    active_ids = active_ids[active_ids > 0].index.tolist()\n",
        "\n",
        "    if len(active_ids) > 0:\n",
        "        train_subset_clean = train_subset[train_subset['unique_id'].isin(active_ids)].copy()\n",
        "\n",
        "        # Run Pipeline\n",
        "        combined_results = run_standard_pipeline(train_subset_clean)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"SUCCESS! PREDICTIONS FROM ALL MODELS:\")\n",
        "        print(\"=\"*50)\n",
        "        print(combined_results.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5a9ec4a5dc4438fbfa016c0bbe2b381",
            "05e2d6ed75a44cd182844c4157338d13",
            "82c46e1be0ab447680d10b54c5d7330e",
            "8753ed44ab8d44ef91b20aee07d956dd",
            "419e618396394b00b1121c27211b8cd7",
            "41bd11b37cf04e1196cf4e91a80526b9",
            "02bcd606cc9b4ecba90dc9143e328a25",
            "cafa1134b4ef4b32a87348eb02475020"
          ]
        },
        "id": "ASbJMUvw7GZQ",
        "outputId": "5c603b8d-52e5-4449-f2dd-206557d8bda7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Generating Future Forecasts (Testing Outputs) ---\n",
            "Forecasting horizon: 39 weeks\n",
            "1. Generating StatsForecast predictions...\n",
            "2. Generating MLForecast (LightGBM) predictions...\n",
            "3. Generating NeuralForecast predictions...\n",
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2025-12-04_16-50-15   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 5                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2025-12-04_16-50-15\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_16-50-15/_train_tune_2025-12-04_16-50-15/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31273)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Seed set to 16\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m 2025-12-04 16:50:38.901610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m E0000 00:00:1764867038.967443   31393 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m E0000 00:00:1764867038.989036   31393 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m W0000 00:00:1764867039.037839   31393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m W0000 00:00:1764867039.037926   31393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m W0000 00:00:1764867039.037930   31393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m W0000 00:00:1764867039.037933   31393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m 2025-12-04 16:50:39.051505: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31273)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.9 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Trainable params: 2.9 M                                                         \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Non-trainable params: 18.5 K                                                    \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Total params: 2.9 M                                                             \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Total estimated model params size (MB): 11                                      \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 16:50:47,028\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_05703_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2972, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31273, ip=172.28.0.12, actor_id=245d523d07c8c022094e2d3801000000, repr=_train_tune)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 44, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in _trainable_func\n",
            "    output = fn()\n",
            "             ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 202, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 350, in _fit_model\n",
            "    model = model.fit(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1915, in fit\n",
            "    return self._fit(\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 602, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 352, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 177, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/module.py\", line 1368, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
            "    ret = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 226, in step\n",
            "    loss = closure()\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "                     ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
            "    step_output = self._step_fn()\n",
            "                  ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1711, in training_step\n",
            "    windows_temporal, static, static_cols = self._create_windows(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 717, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31273)\u001b[0m Epoch 0/-2                    0/1 0:00:00 • -:--:-- 0.00it/s v_num: 0.000       \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m                                                              valid_loss:        \n",
            "\u001b[36m(_train_tune pid=31273)\u001b[0m                                                              16859.066          \n",
            "\n",
            "Trial _train_tune_05703_00000 errored after 0 iterations at 2025-12-04 16:50:47. Total running time: 31s\n",
            "Error file: /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_16-50-15/_train_tune_2025-12-04_16-50-15/driver_artifacts/_train_tune_05703_00000_0_batch_size=32,input_size=195,learning_rate=0.0034,max_steps=1000,random_seed=16,scaler_type=standard,ste_2025-12-04_16-50-15/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31483)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Seed set to 8\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m 2025-12-04 16:51:09.562055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m E0000 00:00:1764867069.590458   31594 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m E0000 00:00:1764867069.598758   31594 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m W0000 00:00:1764867069.619191   31594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m W0000 00:00:1764867069.619241   31594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m W0000 00:00:1764867069.619244   31594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m W0000 00:00:1764867069.619247   31594 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m 2025-12-04 16:51:09.625398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31483)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.8 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Trainable params: 2.8 M                                                         \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Non-trainable params: 15.4 K                                                    \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Total params: 2.8 M                                                             \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Total estimated model params size (MB): 11                                      \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 16:51:17,086\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_05703_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2972, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=31483, ip=172.28.0.12, actor_id=abb996c1442617d0af4ec49f01000000, repr=_train_tune)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 44, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in _trainable_func\n",
            "    output = fn()\n",
            "             ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 202, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 350, in _fit_model\n",
            "    model = model.fit(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1915, in fit\n",
            "    return self._fit(\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 602, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 352, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 177, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/module.py\", line 1368, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
            "    ret = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 226, in step\n",
            "    loss = closure()\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "                     ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
            "    step_output = self._step_fn()\n",
            "                  ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1711, in training_step\n",
            "    windows_temporal, static, static_cols = self._create_windows(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 717, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31483)\u001b[0m Epoch 0/-2                    0/1 0:00:00 • -:--:-- 0.00it/s v_num: 0.000       \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m                                                              valid_loss:        \n",
            "\u001b[36m(_train_tune pid=31483)\u001b[0m                                                              23484.732          \n",
            "\n",
            "Trial _train_tune_05703_00001 errored after 0 iterations at 2025-12-04 16:51:17. Total running time: 1min 1s\n",
            "Error file: /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_16-50-15/_train_tune_2025-12-04_16-50-15/driver_artifacts/_train_tune_05703_00001_1_batch_size=256,input_size=156,learning_rate=0.0019,max_steps=500,random_seed=8,scaler_type=None,step_siz_2025-12-04_16-50-15/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31677)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Seed set to 16\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m 2025-12-04 16:51:40.076641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m E0000 00:00:1764867100.120026   31791 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m E0000 00:00:1764867100.133777   31791 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m W0000 00:00:1764867100.165205   31791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m W0000 00:00:1764867100.165261   31791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m W0000 00:00:1764867100.165266   31791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m W0000 00:00:1764867100.165269   31791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m 2025-12-04 16:51:40.174725: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31677)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Trainable params: 2.6 M                                                         \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Non-trainable params: 9.2 K                                                     \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Total params: 2.6 M                                                             \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Total estimated model params size (MB): 10                                      \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31677)\u001b[0m [2025-12-04 16:51:57,771 E 31677 31723] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31677)\u001b[0m Epoch 999/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m                                                               0.014             \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m                                                               0.014 valid_loss: \n",
            "\u001b[36m(_train_tune pid=31677)\u001b[0m                                                               16254.303         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=31677)\u001b[0m `Trainer.fit` stopped: `max_steps=1000` reached.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Seed set to 3\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m 2025-12-04 16:55:17.597228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m E0000 00:00:1764867317.641974   32751 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m E0000 00:00:1764867317.659323   32751 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m W0000 00:00:1764867317.692343   32751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m W0000 00:00:1764867317.692401   32751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m W0000 00:00:1764867317.692405   32751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m W0000 00:00:1764867317.692409   32751 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m 2025-12-04 16:55:17.701549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=32637)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Trainable params: 2.6 M                                                         \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Non-trainable params: 9.2 K                                                     \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Total params: 2.6 M                                                             \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Total estimated model params size (MB): 10                                      \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=32637)\u001b[0m [2025-12-04 16:55:35,216 E 32637 32683] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=32637)\u001b[0m Epoch 499/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m                                                               0.011             \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m                                                               0.011 valid_loss: \n",
            "\u001b[36m(_train_tune pid=32637)\u001b[0m                                                               16326.287         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=32637)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Seed set to 2\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m 2025-12-04 16:58:45.281448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m E0000 00:00:1764867525.327893   33667 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m E0000 00:00:1764867525.341400   33667 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m W0000 00:00:1764867525.374900   33667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m W0000 00:00:1764867525.374956   33667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m W0000 00:00:1764867525.374961   33667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m W0000 00:00:1764867525.374964   33667 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m 2025-12-04 16:58:45.392011: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=33548)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Trainable params: 2.6 M                                                         \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Non-trainable params: 9.2 K                                                     \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Total params: 2.6 M                                                             \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Total estimated model params size (MB): 10                                      \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Modules in train mode: 31                                                       \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=33548)\u001b[0m [2025-12-04 16:58:59,516 E 33548 33590] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m `Trainer.fit` stopped: `max_steps=500` reached.\n",
            "2025-12-04 17:01:48,986\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-12-04_16-50-15' in 0.0157s.\n",
            "2025-12-04 17:01:48,994\tERROR tune.py:1037 -- Trials did not complete: [_train_tune_05703_00000, _train_tune_05703_00001]\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 16\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=33548)\u001b[0m Epoch 499/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m                                                               0.025             \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m                                                               0.025 valid_loss: \n",
            "\u001b[36m(_train_tune pid=33548)\u001b[0m                                                               18515.104         \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 9.2 K                                                                                        \n",
              "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 30                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 1                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 2.6 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 9.2 K                                                                                        \n",
              "\u001b[1mTotal params\u001b[0m: 2.6 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 10                                                                         \n",
              "\u001b[1mModules in train mode\u001b[0m: 30                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 1                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5a9ec4a5dc4438fbfa016c0bbe2b381",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2025-12-04_17-05-25   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 5                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2025-12-04_17-05-25\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_17-05-25/_train_tune_2025-12-04_17-05-25/driver_artifacts`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35329)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Seed set to 6\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m 2025-12-04 17:05:46.973250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m E0000 00:00:1764867947.001811   35440 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m E0000 00:00:1764867947.012480   35440 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m W0000 00:00:1764867947.035342   35440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m W0000 00:00:1764867947.035389   35440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m W0000 00:00:1764867947.035392   35440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m W0000 00:00:1764867947.035394   35440 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m 2025-12-04 17:05:47.041855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35329)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.8 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Trainable params: 2.8 M                                                         \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Total params: 2.8 M                                                             \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Total estimated model params size (MB): 11                                      \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 17:05:52,894\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_05706_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2972, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=35329, ip=172.28.0.12, actor_id=e899ffb2042af30cf45ca03501000000, repr=_train_tune)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 44, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in _trainable_func\n",
            "    output = fn()\n",
            "             ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 202, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 350, in _fit_model\n",
            "    model = model.fit(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1915, in fit\n",
            "    return self._fit(\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 602, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 352, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 177, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/module.py\", line 1368, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
            "    ret = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 226, in step\n",
            "    loss = closure()\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "                     ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
            "    step_output = self._step_fn()\n",
            "                  ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1711, in training_step\n",
            "    windows_temporal, static, static_cols = self._create_windows(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 717, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35329)\u001b[0m Epoch 0/-2                    0/1 0:00:00 • -:--:-- 0.00it/s v_num: 0.000       \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m                                                              valid_loss:        \n",
            "\u001b[36m(_train_tune pid=35329)\u001b[0m                                                              17604.809          \n",
            "\n",
            "Trial _train_tune_05706_00000 errored after 0 iterations at 2025-12-04 17:05:52. Total running time: 27s\n",
            "Error file: /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_17-05-25/_train_tune_2025-12-04_17-05-25/driver_artifacts/_train_tune_05706_00000_0_batch_size=32,input_size=195,learning_rate=0.0710,max_steps=1400.0000,n_freq_downsample=60_8_1,n_pool_ke_2025-12-04_17-05-25/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35523)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Seed set to 15\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m 2025-12-04 17:06:15.912533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m E0000 00:00:1764867975.943548   35633 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m E0000 00:00:1764867975.955924   35633 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m W0000 00:00:1764867975.976038   35633 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m W0000 00:00:1764867975.976086   35633 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m W0000 00:00:1764867975.976089   35633 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m W0000 00:00:1764867975.976092   35633 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m 2025-12-04 17:06:15.982197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35523)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m │ 3 │ blocks       │ ModuleList    │  3.0 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Trainable params: 3.0 M                                                         \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Total params: 3.0 M                                                             \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Total estimated model params size (MB): 11                                      \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-04 17:06:21,846\tERROR tune_controller.py:1331 -- Trial task failed for trial _train_tune_05706_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 2972, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(\n",
            "                                  ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\", line 1031, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=35523, ip=172.28.0.12, actor_id=eb77da4b692ad0dbd526420d01000000, repr=_train_tune)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 44, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/function_trainable.py\", line 249, in _trainable_func\n",
            "    output = fn()\n",
            "             ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
            "    return trainable(config, **fn_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 202, in _train_tune\n",
            "    _ = self._fit_model(\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_auto.py\", line 350, in _fit_model\n",
            "    model = model.fit(\n",
            "            ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1915, in fit\n",
            "    return self._fit(\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 602, in _fit\n",
            "    trainer.fit(model, datamodule=datamodule)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 465, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 153, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 352, in advance\n",
            "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 192, in run\n",
            "    self._optimizer_step(batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 270, in _optimizer_step\n",
            "    call._call_lightning_module_hook(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 177, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/module.py\", line 1368, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/core/optimizer.py\", line 154, in step\n",
            "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 239, in optimizer_step\n",
            "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 123, in optimizer_step\n",
            "    return optimizer.step(closure=closure, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
            "    ret = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 226, in step\n",
            "    loss = closure()\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/plugins/precision/precision.py\", line 109, in _wrap_closure\n",
            "    closure_result = closure()\n",
            "                     ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 146, in __call__\n",
            "    self._result = self.closure(*args, **kwargs)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 131, in closure\n",
            "    step_output = self._step_fn()\n",
            "                  ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/optimization/automatic.py\", line 319, in _training_step\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 329, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 1711, in training_step\n",
            "    windows_temporal, static, static_cols = self._create_windows(\n",
            "                                            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/neuralforecast/common/_base_model.py\", line 717, in _create_windows\n",
            "    raise Exception(\n",
            "Exception: Time series is too short for training, consider setting a smaller input size or set start_padding_enabled=True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35523)\u001b[0m Epoch 0/-2                    0/1 0:00:00 • -:--:-- 0.00it/s v_num: 0.000       \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m                                                              valid_loss:        \n",
            "\u001b[36m(_train_tune pid=35523)\u001b[0m                                                              16888.574          \n",
            "\n",
            "Trial _train_tune_05706_00001 errored after 0 iterations at 2025-12-04 17:06:21. Total running time: 56s\n",
            "Error file: /tmp/ray/session_2025-12-04_15-19-14_190539_731/artifacts/2025-12-04_17-05-25/_train_tune_2025-12-04_17-05-25/driver_artifacts/_train_tune_05706_00001_1_batch_size=128,input_size=195,learning_rate=0.0017,max_steps=500.0000,n_freq_downsample=40_20_1,n_pool_k_2025-12-04_17-05-25/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35712)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Seed set to 3\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m 2025-12-04 17:06:44.598457: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m E0000 00:00:1764868004.625478   35821 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m E0000 00:00:1764868004.633492   35821 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m W0000 00:00:1764868004.657897   35821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m W0000 00:00:1764868004.657946   35821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m W0000 00:00:1764868004.657949   35821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m W0000 00:00:1764868004.657951   35821 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m 2025-12-04 17:06:44.664101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35712)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Trainable params: 2.6 M                                                         \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Total params: 2.6 M                                                             \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Total estimated model params size (MB): 10                                      \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35712)\u001b[0m [2025-12-04 17:07:01,871 E 35712 35753] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35712)\u001b[0m Epoch 999/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               51007.672         \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               51007.672         \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               valid_loss:       \n",
            "\u001b[36m(_train_tune pid=35712)\u001b[0m                                                               116955.898        \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=35712)\u001b[0m `Trainer.fit` stopped: `max_steps=1000.0` reached.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Seed set to 10\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m 2025-12-04 17:13:06.118442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m E0000 00:00:1764868386.152277   37450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m E0000 00:00:1764868386.160395   37450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m W0000 00:00:1764868386.180696   37450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m W0000 00:00:1764868386.180752   37450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m W0000 00:00:1764868386.180757   37450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m W0000 00:00:1764868386.180761   37450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m 2025-12-04 17:13:06.190099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37331)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.5 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Trainable params: 2.5 M                                                         \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Total params: 2.5 M                                                             \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Total estimated model params size (MB): 9                                       \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37331)\u001b[0m [2025-12-04 17:13:22,781 E 37331 37377] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m `Trainer.fit` stopped: `max_steps=800.0` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37331)\u001b[0m Epoch 799/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               1019.198          \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               1019.198          \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               valid_loss:       \n",
            "\u001b[36m(_train_tune pid=37331)\u001b[0m                                                               18786.342         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37927)\u001b[0m /usr/local/lib/python3.12/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Seed set to 4\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m 2025-12-04 17:15:12.409118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m E0000 00:00:1764868512.438631   38038 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m E0000 00:00:1764868512.446849   38038 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m W0000 00:00:1764868512.468919   38038 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m W0000 00:00:1764868512.468974   38038 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m W0000 00:00:1764868512.468979   38038 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m W0000 00:00:1764868512.468982   38038 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m 2025-12-04 17:15:12.478181: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37927)\u001b[0m ┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m ┃   ┃ Name         ┃ Type          ┃ Params ┃ Mode  ┃ FLOPs ┃\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m ┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m │ 0 │ loss         │ MAE           │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m │ 1 │ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m │ 2 │ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m │ 3 │ blocks       │ ModuleList    │  2.6 M │ train │     0 │\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m └───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Trainable params: 2.6 M                                                         \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Non-trainable params: 0                                                         \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Total params: 2.6 M                                                             \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Total estimated model params size (MB): 10                                      \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Modules in train mode: 34                                                       \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Modules in eval mode: 0                                                         \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Total FLOPs: 0                                                                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_train_tune pid=37927)\u001b[0m [2025-12-04 17:15:29,369 E 37927 37969] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
            "2025-12-04 17:17:56,387\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_train_tune_2025-12-04_17-05-25' in 0.0116s.\n",
            "2025-12-04 17:17:56,396\tERROR tune.py:1037 -- Trials did not complete: [_train_tune_05706_00000, _train_tune_05706_00001]\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 10\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m `Trainer.fit` stopped: `max_steps=800.0` reached.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m Epoch 799/-2 ━━━━━━━━━━━━━━━━━ 1/1 0:00:00 • 0:00:00 0.00it/s v_num: 0.000      \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               train_loss_step:  \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               16240.426         \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               train_loss_epoch: \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               16240.426         \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               valid_loss:       \n",
            "\u001b[36m(_train_tune pid=37927)\u001b[0m                                                               36866.355         \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name         </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ blocks       │ ModuleList    │  2.5 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName        \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss         │ MAE           │      0 │ eval  │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ padder_train │ ConstantPad1d │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ scaler       │ TemporalNorm  │      0 │ train │     0 │\n",
              "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ blocks       │ ModuleList    │  2.5 M │ train │     0 │\n",
              "└───┴──────────────┴───────────────┴────────┴───────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.5 M                                                                                            \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 2.5 M                                                                                                \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 9                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 33                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 1                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 2.5 M                                                                                            \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 2.5 M                                                                                                \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 9                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 33                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 1                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82c46e1be0ab447680d10b54c5d7330e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=800.0` reached.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "419e618396394b00b1121c27211b8cd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02bcd606cc9b4ecba90dc9143e328a25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging future forecasts...\n",
            "Merging TimeGPT results...\n",
            "\n",
            "Success! Future forecasts generated.\n",
            "   index unique_id         ds      Naive  SeasonalNaive        AutoETS      AutoARIMA       LightGBM     AutoNBEATS      AutoNHITS     TimeGPT\n",
            "0      0     10_72 2012-11-02  121126.83      164085.50  121731.372285  146823.630044  119293.290232  145975.578125  139059.859375  101126.766\n",
            "1      1     10_72 2012-11-09  121126.83      165484.28  154154.779805  152522.285140  120565.613327  137477.546875  165292.718750  137822.900\n",
            "2      2     10_72 2012-11-16  121126.83      142730.01  125783.764293  131582.211216  113009.388415   91980.015625  135245.031250  172166.800\n",
            "3      3     10_72 2012-11-23  121126.83      630999.19  721370.335147  620616.833776  253823.819253  401640.437500  547326.375000  269151.940\n",
            "4      4     10_72 2012-11-30  121126.83      156039.04  189763.215386  145979.638015  142908.368103  121521.179688  217144.625000  212760.480\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 5. Generate Testing Outputs (Final Corrected Version)\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "from statsforecast import StatsForecast\n",
        "from statsforecast.models import Naive, SeasonalNaive, AutoETS, AutoARIMA\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.target_transforms import Differences\n",
        "from lightgbm import LGBMRegressor\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNBEATS, AutoNHITS\n",
        "from neuralforecast.losses.pytorch import MAE  # Import MAE for stability\n",
        "\n",
        "def generate_future_forecasts(df_train, df_test):\n",
        "    print(\"\\n--- Generating Future Forecasts (Testing Outputs) ---\")\n",
        "\n",
        "    # 1. Configuration\n",
        "    FREQ = 'W-FRI'\n",
        "    # Calculate horizon based on the test set\n",
        "    HORIZON = df_test.groupby('unique_id')['ds'].count().max()\n",
        "    print(f\"Forecasting horizon: {HORIZON} weeks\")\n",
        "\n",
        "    # 2. StatsForecast\n",
        "    print(\"1. Generating StatsForecast predictions...\")\n",
        "    sf = StatsForecast(\n",
        "        models=[\n",
        "            Naive(),\n",
        "            SeasonalNaive(season_length=52),\n",
        "            AutoETS(season_length=52),\n",
        "            AutoARIMA(season_length=52)\n",
        "        ],\n",
        "        freq=FREQ,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    sf_fut = sf.forecast(df=df_train[['unique_id', 'ds', 'y']], h=HORIZON)\n",
        "    sf_fut = sf_fut.reset_index()\n",
        "\n",
        "    # 3. MLForecast (LightGBM)\n",
        "    print(\"2. Generating MLForecast (LightGBM) predictions...\")\n",
        "    lgbm = LGBMRegressor(verbosity=-1, random_state=42)\n",
        "\n",
        "    mlf = MLForecast(\n",
        "        models=[lgbm],\n",
        "        freq=FREQ,\n",
        "        lags=[1, 4, 52],\n",
        "        target_transforms=[Differences([1])],\n",
        "        date_features=['month', 'week'],\n",
        "        num_threads=4\n",
        "    )\n",
        "\n",
        "    # Define columns\n",
        "    ml_train_cols = ['unique_id', 'ds', 'y', 'Type', 'Size', 'Temperature',\n",
        "                     'Fuel_Price', 'CPI', 'Unemployment', 'IsHoliday',\n",
        "                     'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "\n",
        "    # Fit (Defining Type and Size as static)\n",
        "    mlf.fit(df=df_train[ml_train_cols], static_features=['Type', 'Size'])\n",
        "\n",
        "    # The model already knows 'Type' and 'Size' from training.\n",
        "    cols_to_drop = ['y', 'Weekly_Sales', 'Type', 'Size']\n",
        "    X_df_future = df_test.drop(columns=cols_to_drop, errors='ignore')\n",
        "\n",
        "    ml_fut = mlf.predict(h=HORIZON, X_df=X_df_future)\n",
        "    ml_fut = ml_fut.rename(columns={'LGBMRegressor': 'LightGBM'})\n",
        "\n",
        "    # 4. NeuralForecast (Auto Models Stabilized)\n",
        "    print(\"3. Generating NeuralForecast predictions...\")\n",
        "\n",
        "    # STABILITY SETTINGS:\n",
        "    nf = NeuralForecast(\n",
        "        models=[\n",
        "            AutoNBEATS(\n",
        "                h=HORIZON,\n",
        "                loss=MAE(),\n",
        "                num_samples=5\n",
        "            ),\n",
        "            AutoNHITS(\n",
        "                h=HORIZON,\n",
        "                loss=MAE(),\n",
        "                num_samples=5\n",
        "            )\n",
        "        ],\n",
        "        freq=FREQ\n",
        "    )\n",
        "\n",
        "    nf.fit(df=df_train[['unique_id', 'ds', 'y']])\n",
        "    nf_fut = nf.predict(futr_df=df_test[['unique_id', 'ds']])\n",
        "\n",
        "    # 5. Merge All Results\n",
        "\n",
        "    print(\"Merging future forecasts...\")\n",
        "    final_fut = sf_fut.copy()\n",
        "    final_fut = final_fut.merge(ml_fut, on=['unique_id', 'ds'], how='left')\n",
        "    final_fut = final_fut.merge(nf_fut, on=['unique_id', 'ds'], how='left')\n",
        "\n",
        "    return final_fut\n",
        "\n",
        "# --- EXECUTE ---\n",
        "if 'train_subset' in globals() and 'test_subset' in globals():\n",
        "\n",
        "    # Filter for active data to ensure stability\n",
        "    active_ids = train_subset.groupby('unique_id')['y'].sum()\n",
        "    active_ids = active_ids[active_ids > 0].index.tolist()\n",
        "    train_clean = train_subset[train_subset['unique_id'].isin(active_ids)].copy()\n",
        "    test_clean = test_subset[test_subset['unique_id'].isin(active_ids)].copy()\n",
        "\n",
        "    # RUN FUNCTION\n",
        "    future_forecasts = generate_future_forecasts(train_clean, test_clean)\n",
        "\n",
        "    # MERGE TIMEGPT IF AVAILABLE\n",
        "    # Checks if TimeGPT was run in Step 3 and merges it if it exists\n",
        "    if 'tgpt_fcst' in globals() and not tgpt_fcst.empty:\n",
        "        print(\"Merging TimeGPT results...\")\n",
        "        cols_to_merge = ['unique_id', 'ds', 'TimeGPT']\n",
        "        if all(col in tgpt_fcst.columns for col in cols_to_merge):\n",
        "             future_forecasts = future_forecasts.merge(\n",
        "                 tgpt_fcst[cols_to_merge],\n",
        "                 on=['unique_id', 'ds'],\n",
        "                 how='left'\n",
        "             )\n",
        "\n",
        "    print(\"\\nSuccess! Future forecasts generated.\")\n",
        "    print(future_forecasts.head())\n",
        "\n",
        "else:\n",
        "    print(\"Error: 'train_subset' or 'test_subset' not found. Please run Step 2 (Data Loading) first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQj1yszz7aqa",
        "outputId": "6ef0b2df-ecf5-47c5-84b9-abcfa29b71ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Calculating Global Accuracy Metrics ---\n",
            "           Model           ME           MAE          RMSE      MAPE\n",
            "5     AutoNBEATS  -850.619566   7107.947170   9782.697450  5.175090\n",
            "2        AutoETS  -857.830317   7845.232619  10662.438821  5.672372\n",
            "3      AutoARIMA -2206.756063   7418.543313  11411.103296  5.473035\n",
            "6      AutoNHITS -1811.165523   9425.748159  12897.903357  6.778289\n",
            "4       LightGBM -5034.945115  10399.368105  14645.473281  7.725298\n",
            "1  SeasonalNaive  1012.752825  11298.365025  15861.602483  8.184313\n",
            "0          Naive -2025.840950  12065.408550  15934.427679  8.689676\n",
            "\n",
            "--- Model Leaderboard (Wins per Series) ---\n",
            "          Winner  count\n",
            "0     AutoNBEATS      9\n",
            "1      AutoARIMA      4\n",
            "2        AutoETS      3\n",
            "3  SeasonalNaive      3\n",
            "4      AutoNHITS      1\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 6. Evaluation Metrics\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "def calculate_metrics(cv_df):\n",
        "    # Identify model columns (exclude ID/Date/Target columns)\n",
        "    models = [c for c in cv_df.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "    results = []\n",
        "\n",
        "    for model in models:\n",
        "        y_true = cv_df['y']\n",
        "        y_pred = cv_df[model]\n",
        "\n",
        "        # Drop NaNs for metric calculation (in case of alignment issues)\n",
        "        valid_mask = ~np.isnan(y_pred)\n",
        "        y_true_clean = y_true[valid_mask]\n",
        "        y_pred_clean = y_pred[valid_mask]\n",
        "\n",
        "        if len(y_true_clean) == 0:\n",
        "            continue\n",
        "\n",
        "        # Rubric Metrics\n",
        "        me = np.mean(y_true_clean - y_pred_clean)\n",
        "        mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "\n",
        "        # MAPE (handling zeros)\n",
        "        mask = y_true_clean != 0\n",
        "        if mask.any():\n",
        "            mape = np.mean(np.abs((y_true_clean[mask] - y_pred_clean[mask]) / y_true_clean[mask])) * 100\n",
        "        else:\n",
        "            mape = np.nan\n",
        "\n",
        "        results.append({'Model': model, 'ME': me, 'MAE': mae, 'RMSE': rmse, 'MAPE': mape})\n",
        "\n",
        "    return pd.DataFrame(results).sort_values(by='RMSE')\n",
        "\n",
        "def count_winners(cv_df):\n",
        "    models = [c for c in cv_df.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "    errors = cv_df.copy()\n",
        "\n",
        "    # Calculate absolute error for every row\n",
        "    for m in models:\n",
        "        errors[m] = (errors['y'] - errors[m]).abs()\n",
        "\n",
        "    # Find model with lowest MAE per series\n",
        "    series_mae = errors.groupby('unique_id')[models].mean()\n",
        "    series_mae['Winner'] = series_mae.idxmin(axis=1)\n",
        "\n",
        "    return series_mae['Winner'].value_counts().reset_index()\n",
        "\n",
        "# EXECUTE THE FUNCTIONS\n",
        "# We look for 'combined_results' which comes from Step 4 (The Cross-Validation Step)\n",
        "if 'combined_results' in globals():\n",
        "    print(\"\\n--- Calculating Global Accuracy Metrics ---\")\n",
        "    metrics_df = calculate_metrics(combined_results)\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\n--- Model Leaderboard (Wins per Series) ---\")\n",
        "    winners_df = count_winners(combined_results)\n",
        "    print(winners_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "V_IOb0Mr7lBq",
        "outputId": "53b6961c-875c-48cc-d6ba-9082c0c1a1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Main Execution Pipeline...\n",
            "\n",
            "Loading data...\n",
            "\n",
            "--- DIAGNOSTIC CHECK ---\n",
            "Total Sum of 'y' (Sales): 402,568,823.37\n",
            "STATUS: Data verified. Sales column 'y' is populated.\n",
            "------------------------\n",
            "\n",
            "Data Prepared. Modeling 20 series.\n",
            "[StatsForecast  ] Training: Naive, SeasonalNaive, AutoETS, AutoARIMA\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1434522408.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# 2. Run Standard Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mfinal_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_standard_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# 3. Run TimeGPT (Remote)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2827516737.py\u001b[0m in \u001b[0;36mrun_standard_pipeline\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[0;32m---> 37\u001b[0;31m     stats_cv = sf.cross_validation(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ds'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHORIZON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHORIZON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_windows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_WINDOWS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsforecast/core.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(self, h, df, n_windows, step_size, test_size, input_size, level, fitted, refit, prediction_intervals, id_col, time_col, target_col)\u001b[0m\n\u001b[1;32m   1524\u001b[0m     ):\n\u001b[1;32m   1525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1526\u001b[0;31m             return super().cross_validation(\n\u001b[0m\u001b[1;32m   1527\u001b[0m                 \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsforecast/core.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(self, h, df, n_windows, step_size, test_size, input_size, level, fitted, refit, prediction_intervals, id_col, time_col, target_col)\u001b[0m\n\u001b[1;32m    977\u001b[0m             )\n\u001b[1;32m    978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             res_fcsts = self._cross_validation_parallel(\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsforecast/core.py\u001b[0m in \u001b[0;36m_cross_validation_parallel\u001b[0;34m(self, h, test_size, step_size, input_size, fitted, level, refit, target_col)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 )\n\u001b[1;32m   1192\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mfcsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"forecasts\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mfcsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 7. Main Execution (Corrected for Unified Pipeline)\n",
        "# ==========================================\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Check if functions from previous cells are defined\n",
        "required_funcs = ['load_and_prep_data', 'run_standard_pipeline', 'run_timegpt_pipeline',\n",
        "                  'generate_future_forecasts', 'calculate_metrics', 'count_winners']\n",
        "\n",
        "if not all(func in globals() for func in required_funcs):\n",
        "    print(\"Error: Required functions are missing.\")\n",
        "    print(\"Please make sure you have run ALL previous cells (Steps 2-6) before running this one.\")\n",
        "else:\n",
        "    print(\"Starting Main Execution Pipeline...\\n\")\n",
        "\n",
        "    # 1. Load Data\n",
        "    train_subset, test_subset = load_and_prep_data()\n",
        "\n",
        "    if train_subset is not None:\n",
        "        # 2. Run Standard Model\n",
        "        final_eval = run_standard_pipeline(train_subset)\n",
        "\n",
        "        # 3. Run TimeGPT (Remote)\n",
        "        tgpt_cv, tgpt_fcst = run_timegpt_pipeline(train_subset, test_subset, horizon=4, n_windows=5)\n",
        "\n",
        "        # 4. Merge TimeGPT into Evaluation Results\n",
        "        print(\"Merging TimeGPT results...\")\n",
        "        merge_keys = ['unique_id', 'ds', 'cutoff']\n",
        "\n",
        "        if not tgpt_cv.empty and 'TimeGPT' in tgpt_cv.columns:\n",
        "            # Drop 'y' from TimeGPT CV to avoid duplicates if it exists\n",
        "            tgpt_clean = tgpt_cv.drop(columns=['y'], errors='ignore')\n",
        "            final_eval = final_eval.merge(tgpt_clean, on=merge_keys, how='left')\n",
        "\n",
        "        # 5. Generate Future Forecasts\n",
        "        future_forecasts = generate_future_forecasts(train_subset, test_subset)\n",
        "\n",
        "        # Merge TimeGPT Future Forecasts if available\n",
        "        if not tgpt_fcst.empty and 'TimeGPT' in tgpt_fcst.columns:\n",
        "             future_forecasts = future_forecasts.merge(\n",
        "                 tgpt_fcst[['unique_id', 'ds', 'TimeGPT']],\n",
        "                 on=['unique_id', 'ds'],\n",
        "                 how='left'\n",
        "             )\n",
        "\n",
        "        # 6. Metrics & Winners\n",
        "        metrics_df = calculate_metrics(final_eval)\n",
        "        winners_df = count_winners(final_eval)\n",
        "\n",
        "        print(\"\\n--- Final Metrics ---\")\n",
        "        print(metrics_df)\n",
        "        print(\"\\n--- Model Winners (Count by Series) ---\")\n",
        "        print(winners_df)\n",
        "\n",
        "        # 7. Save CSVs\n",
        "        final_eval.to_csv('final_evaluation_output.csv', index=False)\n",
        "        metrics_df.to_csv('final_metrics_summary.csv', index=False)\n",
        "        future_forecasts.to_csv('testing_outputs.csv', index=False)\n",
        "        print(\"\\n Files Saved: final_evaluation_output.csv, final_metrics_summary.csv, testing_outputs.csv\")\n",
        "\n",
        "        # 8. Plotting\n",
        "        # Check if we have data to plot\n",
        "        if not final_eval.empty:\n",
        "            u_id = final_eval['unique_id'].unique()[0]\n",
        "            subset = final_eval[final_eval['unique_id'] == u_id]\n",
        "\n",
        "            plt.figure(figsize=(14, 6))\n",
        "\n",
        "            # Plot Actuals\n",
        "            if 'y' in subset.columns:\n",
        "                plt.plot(subset['ds'], subset['y'], label='Actual', color='black', linewidth=2)\n",
        "\n",
        "            # Plot models dynamically\n",
        "            plot_models = [c for c in subset.columns if c not in ['unique_id', 'ds', 'cutoff', 'y']]\n",
        "            for m in plot_models:\n",
        "                # Plot only if column is numeric\n",
        "                if pd.api.types.is_numeric_dtype(subset[m]):\n",
        "                    plt.plot(subset['ds'], subset[m], label=m, alpha=0.7)\n",
        "\n",
        "            plt.title(f\"Forecast Models vs Actual: {u_id}\")\n",
        "            plt.legend()\n",
        "            plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02bcd606cc9b4ecba90dc9143e328a25": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cafa1134b4ef4b32a87348eb02475020",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "05e2d6ed75a44cd182844c4157338d13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "165bba3b67174d3a8e9cf02d0420a0d3": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_776a083e13504f6b80bbf0908cec4d40",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "2209404beb6840a79cf0e4ca1640eadf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bde3429839241c78b56644d387f00d8": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cc25f337b0c0499baa683f80fcaab583",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 999/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 11.000 train_loss_step: 0.086</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.104             </span>\n</pre>\n",
                  "text/plain": "Epoch 999/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 11.000 train_loss_step: 0.086\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.104             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "419e618396394b00b1121c27211b8cd7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_41bd11b37cf04e1196cf4e91a80526b9",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "41bd11b37cf04e1196cf4e91a80526b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776a083e13504f6b80bbf0908cec4d40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a1e0e5a458433985cc96d6332abc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c46e1be0ab447680d10b54c5d7330e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8753ed44ab8d44ef91b20aee07d956dd",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 799/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 16.000 train_loss_step:      </span>\n                                                                               <span style=\"font-style: italic\">1335.244 train_loss_epoch: 1343.614 </span>\n</pre>\n",
                  "text/plain": "Epoch 799/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 16.000 train_loss_step:      \u001b[0m\n                                                                               \u001b[3m1335.244 train_loss_epoch: 1343.614 \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "8753ed44ab8d44ef91b20aee07d956dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a112c8827a5d4fbca42d0e7eed3c73c7": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2209404beb6840a79cf0e4ca1640eadf",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicting <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span>  \n</pre>\n",
                  "text/plain": "Predicting \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "cafa1134b4ef4b32a87348eb02475020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc25f337b0c0499baa683f80fcaab583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a9ec4a5dc4438fbfa016c0bbe2b381": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_05e2d6ed75a44cd182844c4157338d13",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 999/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 15.000 train_loss_step: 0.072</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.072             </span>\n</pre>\n",
                  "text/plain": "Epoch 999/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 15.000 train_loss_step: 0.072\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.072             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "fbc59f91b6df49cc9163c5cc6b3be16e": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_79a1e0e5a458433985cc96d6332abc7c",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 499/-2 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 1/1 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:00 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">0.00it/s</span> <span style=\"font-style: italic\">v_num: 13.000 train_loss_step: 0.024</span>\n                                                                               <span style=\"font-style: italic\">train_loss_epoch: 0.029             </span>\n</pre>\n",
                  "text/plain": "Epoch 499/-2 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 1/1 \u001b[2m0:00:00 • 0:00:00\u001b[0m \u001b[2;4m0.00it/s\u001b[0m \u001b[3mv_num: 13.000 train_loss_step: 0.024\u001b[0m\n                                                                               \u001b[3mtrain_loss_epoch: 0.029             \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
